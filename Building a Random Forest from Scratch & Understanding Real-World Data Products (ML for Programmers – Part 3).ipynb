{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fastai.imports import *\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x+np.random.uniform(-0.2,0.2,x.shape)\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=x[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, x_val = x1[:40], x1[40:]\n",
    "y_trn, y_val = y[:40], y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor().fit(x_trn, y_trn)\n",
    "plt.scatter(y_trn, m.predict(x_trn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Machine Learning: Lesson 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/bulldozers/\"\n",
    "\n",
    "df_raw = pd.read_feather('tmp/bulldozers-raw')\n",
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')\n",
    "\n",
    "def split_vals(a,n): return a[:n], a[n:]\n",
    "n_valid = 12000\n",
    "n_trn = len(df_trn)-n_valid\n",
    "\n",
    "X_train, X_valid = split_vals(df_trn, n_trn)\n",
    "y_train, y_valid = split_vals(y_trn, n_trn)\n",
    "\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub = X_train[['YearMade', 'MachineHoursCurrentMeter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n",
    "       np.random.seed(42)\n",
    "       self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n",
    "       self.trees = [self.create_tree() for i in range(n_trees)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def create_tree(self):\n",
    "       rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n",
    "       return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def predict(self, x):\n",
    "       return np.mean([t.predict(x) for t in self.trees], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeEnsemble():\n",
    "   def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n",
    "       np.random.seed(42)\n",
    "       self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n",
    "       self.trees = [self.create_tree() for i in range(n_trees)]\n",
    "\n",
    "   def create_tree(self):\n",
    "       rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n",
    "       return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)\n",
    "       \n",
    "   def predict(self, x):\n",
    "       return np.mean([t.predict(x) for t in self.trees], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "  def __init__(self, x, y, idxs=None, min_leaf=5):\n",
    "      if idxs is None: idxs=np.arange(len(y))\n",
    "      self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf ##define x,y,index and minimum leaf size\n",
    "      self.n,self.c = len(idxs), x.shape[1]  ##number of rows and columns\n",
    "      self.val = np.mean(y[idxs])  \n",
    "      self.score = float('inf')\n",
    "      self.find_varsplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def find_varsplit(self):\n",
    "      for i in range(self.c): self.find_better_split(i) #check for each column in the dataset\n",
    "   \n",
    "def find_varsplit(self):\n",
    "       for i in range(self.c): self.find_better_split(i)\n",
    "\n",
    "  @property\n",
    "  def split_name(self): return self.x.columns[self.var_idx]\n",
    "\n",
    "  @property\n",
    "  def split_col(self):\n",
    "      return self.x.values[self.idxs,self.var_idx]\n",
    "\n",
    "  @property\n",
    "  def is_leaf(self): return self.score == float('inf')\n",
    "\n",
    "  def __repr__(self):\n",
    "      s = f'n: {self.n}; val:{self.val}'\n",
    "      if not self.is_leaf:\n",
    "          s += f'; score:{self.score}; split:{self.split}; var:\n",
    "                 {self.split_name}'\n",
    "      return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TreeEnsemble(X_train, y_train, n_trees=10, sample_sz=1000,min_leaf=3)\n",
    "m.trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def find_better_split(self, var_idx):\n",
    "   x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]\n",
    "\n",
    "   for i in range(self.n):\n",
    "       lhs = x<=x[i]\n",
    "       rhs = x>x[i]\n",
    "       if rhs.sum()<self.min_leaf or lhs.sum()<self.min_leaf: continue\n",
    "       lhs_std = y[lhs].std()\n",
    "       rhs_std = y[rhs].std()\n",
    "       curr_score = lhs_std*lhs.sum() + rhs_std*rhs.sum()\n",
    "       if curr_score<self.score: \n",
    "           self.var_idx,self.score,self.split = var_idx,curr_score,x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_better_split(tree,1)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_better_split(tree,0);\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = TreeEnsemble(x_sub, y_train, 1, 1000)\n",
    "tree = ens.trees[0]\n",
    "x_samp,y_samp = tree.x, tree.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, max_depth=1, bootstrap=False)\n",
    "m.fit(x_samp, y_samp)\n",
    "draw_tree(m.estimators_[0], x_samp, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(x)\n",
    "sort_y,sort_x = y[sort_idx], x[sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs_cnt,rhs_sum,rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum()\n",
    "lhs_cnt,lhs_sum,lhs_sum2 = 0,0.,0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = TreeEnsemble(x_sub, y_train, 1, 1000).trees[0]\n",
    "def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)\n",
    "def find_better_split_foo(self, var_idx):\n",
    "x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]\n",
    "\n",
    "sort_idx = np.argsort(x)\n",
    "sort_y,sort_x = y[sort_idx], x[sort_idx]\n",
    "\n",
    "rhs_cnt,rhs_sum,rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum()\n",
    "lhs_cnt,lhs_sum,lhs_sum2 = 0,0.,0.\n",
    "\n",
    "for i in range(0,self.n-self.min_leaf-1):\n",
    "  xi,yi = sort_x[i],sort_y[i]\n",
    "  lhs_cnt += 1; rhs_cnt -= 1\n",
    "  lhs_sum += yi; rhs_sum -= yi\n",
    "  lhs_sum2 += yi**2; rhs_sum2 -= yi**2\n",
    "  if i<self.min_leaf or xi==sort_x[i+1]:\n",
    "    continue\n",
    "  \n",
    "  lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n",
    "  rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n",
    "  curr_score = lhs_std*lhs_cnt + rhs_std*rhs_cnt\n",
    "  if curr_score<self.score:\n",
    "    self.var_idx,self.score,self.split = var_idx,curr_score,xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit find_better_split_foo(tree,1)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTree.find_better_split = find_better_split_foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_varsplit(self):\n",
    "      for i in range(self.c): self.find_better_split(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_varsplit(self):\n",
    "  for i in range(self.c): self.find_better_split(i)\n",
    "  if self.is_leaf: return\n",
    "  x = self.split_col\n",
    "  lhs = np.nonzero(x<=self.split)[0]\n",
    "  rhs = np.nonzero(x>self.split)[0]\n",
    "  self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])\n",
    "  self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])\n",
    "\n",
    "DecisionTree.find_varsplit = find_varsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, max_depth=2,  bootstrap=False)\n",
    "m.fit(x_samp, y_samp)\n",
    "draw_tree(m.estimators_[0], x_samp, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = TreeEnsemble(x_sub, y_train, 1, 1000).trees[0]\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.lhs\n",
    "tree.rhs\n",
    "tree.lhs.lhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "return np.array([self.predict_row(xi) for xi in x])\n",
    "\n",
    "def predict_row(self, xi):\n",
    "if self.is_leaf: return self.val\n",
    "t = self.lhs if xi[self.var_idx]<=self.split else self.rhs\n",
    "return t.predict_row(xi)\n",
    "DecisionTree.predict_row = predict_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['MachineID', 'YearMade', 'MachineHoursCurrentMeter',\n",
    "'ProductSize', 'Enclosure','Coupler_System', 'saleYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time tree = TreeEnsemble(X_train[cols], y_train, 1, 1000).trees[0]\n",
    "x_samp,y_samp = tree.x, tree.y\n",
    "\n",
    "CPU times: user 288 ms, sys: 12 ms, total: 300 ms\n",
    "Wall time: 297 ms\n",
    "\n",
    "plt.scatter(preds, y_valid, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(preds, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, min_samples_leaf=5, bootstrap=False)\n",
    "%time m.fit(x_samp, y_samp)\n",
    "preds = m.predict(X_valid[cols].values)\n",
    "plt.scatter(preds, y_valid, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(preds, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeEnsemble():\n",
    "    def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n",
    "        np.random.seed(42)\n",
    "        self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n",
    "        self.trees = [self.create_tree() for i in range(n_trees)]\n",
    "\n",
    "    def create_tree(self):\n",
    "        idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n",
    "        return DecisionTree(self.x.iloc[idxs], self.y[idxs], \n",
    "                    idxs=np.array(range(self.sample_sz)), min_leaf=self.min_leaf)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.mean([t.predict(x) for t in self.trees], axis=0)\n",
    "\n",
    "def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, x, y, idxs, min_leaf=5):\n",
    "        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf\n",
    "        self.n,self.c = len(idxs), x.shape[1]\n",
    "        self.val = np.mean(y[idxs])\n",
    "        self.score = float('inf')\n",
    "        self.find_varsplit()\n",
    "        \n",
    "    def find_varsplit(self):\n",
    "        for i in range(self.c): self.find_better_split(i)\n",
    "        if self.score == float('inf'): return\n",
    "        x = self.split_col\n",
    "        lhs = np.nonzero(x<=self.split)[0]\n",
    "        rhs = np.nonzero(x>self.split)[0]\n",
    "        self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])\n",
    "        self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])\n",
    "\n",
    "    def find_better_split(self, var_idx):\n",
    "        x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]\n",
    "        sort_idx = np.argsort(x)\n",
    "        sort_y,sort_x = y[sort_idx], x[sort_idx]\n",
    "        rhs_cnt,rhs_sum,rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum()\n",
    "        lhs_cnt,lhs_sum,lhs_sum2 = 0,0.,0.\n",
    "\n",
    "        for i in range(0,self.n-self.min_leaf):\n",
    "            xi,yi = sort_x[i],sort_y[i]\n",
    "            lhs_cnt += 1; rhs_cnt -= 1\n",
    "            lhs_sum += yi; rhs_sum -= yi\n",
    "            lhs_sum2 += yi**2; rhs_sum2 -= yi**2\n",
    "            if i<self.min_leaf-1 or xi==sort_x[i+1]:\n",
    "                continue\n",
    "\n",
    "            lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n",
    "            rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n",
    "            curr_score = lhs_std*lhs_cnt + rhs_std*rhs_cnt\n",
    "            if curr_score<self.score: \n",
    "                self.var_idx,self.score,self.split = var_idx,curr_score,xi\n",
    "\n",
    "    @property\n",
    "    def split_name(self): return self.x.columns[self.var_idx]\n",
    "    \n",
    "    @property\n",
    "    def split_col(self): return self.x.values[self.idxs,self.var_idx]\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self): return self.score == float('inf')\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = f'n: {self.n}; val:{self.val}'\n",
    "        if not self.is_leaf:\n",
    "            s += f'; score:{self.score}; split:{self.split}; var:{self.split_name}'\n",
    "        return s\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.array([self.predict_row(xi) for xi in x])\n",
    "\n",
    "    def predict_row(self, xi):\n",
    "        if self.is_leaf: return self.val\n",
    "        t = self.lhs if xi[self.var_idx]<=self.split else self.rhs\n",
    "        return t.predict_row(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = TreeEnsemble(X_train[cols], y_train, 5, 1000)\n",
    "preds = ens.predict(X_valid[cols].values)\n",
    "plt.scatter(y_valid, preds, alpha=0.1, s=6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(y_valid, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
